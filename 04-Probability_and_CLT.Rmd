# (PART) Probability models and the Central Limit Theorem {-}

# Week 4 Overview {-}

|                 |                                   |
|-----------------|-----------------------------------|
| **Dates**       | 13 February 2023 - 17 February 2023 |
| **Reading**     | **Required:** SCIU4T4 Workbook chapters 14-15  |
|                 | **Recommended:** @Navarro2022 [Chapter 7](https://davidfoxcroft.github.io/lsj-book/07-Introduction-to-probability.html)    |
|                 | **Optional:**  @Rowntree2018 Chapter 4 |
| **Lectures**    | 4.1: Probability models (17 min.) |
|                 | 4.2: Probabilities to make predictions (12 min.) |
|                 | 4.3: Probability distributions (11 min.) |
|                 | 4.4: Predictions using sample statistics (16 min.) |
|                 | 4.5: Jamovi procedures |
| **Practical**   | Probability and simulation ([Chapter 16](#Chapter_16))       |
|                 |   Room: Cottrell 2A17         |
|                 |   Group A: 15 FEB 2023 (WED) 13:05-15:55 |
|                 |   Group B: 16 FEB 2023 (THU) 09:05-11:55 |
| **Help hours**  | Ian Jones                       |
|                 |   Room: Cottrell 1A13           |
|                 |   17 FEB 2023 (FRI) 15:05-17:55 |
| **Assessments** | Week 4 Practice quiz on Canvas  |



# Introduction to probability models

Suppose that we flip a fair coin over a flat surface.
There are two possibilities for how the coin lands on the surface.
Either the coin lands on one side (heads) or the other side (tails), but we do not know the outcome in advance.
If these two events (heads or tails) are equally likely, then we could reason that there is a 50\% chance that a flipped coin will land heads up and a 50\% chance that it will land heads down.
What do we actually mean when we say this?
For example, when we say that there is a 50\% chance of the coin landing heads up, are we making a claim about our own knowledge, how coins work, or how the world works?
We might mean that we simply do not know whether or not the coin will land heads up, so a 50-50 chance just reflects our best guess about what will actually happen when the coin is flipped.
Alternatively, we might reason that if a fair coin were to be flipped many times, all else being equal, then about half of flips should end heads up, so a 50\% chance is a reasonable prediction of what will happen in any given flip.
Or, perhaps we reason that events such as coin flips really are guided by chance on some deeper fundamental level, such that our 50\% chance reflects some real causal metaphysical process in the world.
These are questions concerning the philosophy of probability.
The philosophy of probability is an interesting sub-discipline in its own right, with implications that can and do affect how researchers do statistics [@Edwards1972; @Mayo1996; @Gelman2013; @Suarez2020; @Mayo2021; @Navarro2022].

In this chapter, we will not worry about the philosophy of probability[^12] and instead focus on the mathematical rules of probability as applied to statistics.
These rules are important for predicting real-world events in the biological and environmental sciences.
For example, we might need to make predictions concerning the risk of disease spreading in a population, or the risk of extreme events such as droughts occurring given increasing global temperatures.
Probability is also important for testing scientific hypotheses.
For example, if we sample two different groups and calculate that they have different means (e.g., two different fields have different mean soil nitrogen concentrations), we might want to know the probability that this difference between means could have arisen by chance.
Here we will introduce practicals example of probability, then introduce some common probability distributions.

[^12]: In the interest of transparency, this book presents a *frequentist* interpretation of probability [@Mayo1996]. While this approach does reflect the philosophical inclinations of the author, the reason for working from this interpretation has more to do with the statistical tests that are most appropriate for an introductory statistics module, which are also the tests most widely used in the biological and environmental sciences.


## An instructive example

Probability focuses on the outcomes of trials, such as the **outcome** (heads or tails) of the **trial** of a coin flip.
The probability of an specific outcome is the relative number of times it is expected to happen given a large number of trials,

$$P(outcome) = \frac{Number\:of\:times\:outcome\:occurs}{Total\:number\:of\:trials}.$$

For the outcome of a flipped coin landing on heads,

$$P(heads) = \frac{Flips\:landing\:on\:heads}{Total\:number\:of\:flips}.$$

As the total number of flips becomes very large, the number of flips that land on heads should get closer and closer to half the total, $1/2$ or $0.5$ (more on this later).
The above equations use the notation $P(X)$ to define the probability ($P$) of some event ($X$) happening.
Note that the number of times an outcome occurs cannot be less than 0, so $P(X) \geq 0$ must always be true.
Similarly, the number of times an outcome occurs cannot be greater than the number of trials; the most frequently it can happen is in *every* trial, in which case the top and bottom of the fraction has the same value.
Hence, $P(X) \leq 1$ must also always be true.
Probabilities therefore range from 0 (an outcome *never* happens) to 1 (an outcome *always* happens).

It might be more familiar and intuitive at first to think in terms of percentages (i.e., from 0-100\% chance of an outcome, rather than from 0-1), but there are good mathematical reasons for thinking about probability on a 0-1 scale (it makes calculations easier).
For example, suppose we have two coins, and we want to calculate the probability that they will both land on heads if we flip them at the same time.
That is, we want to know the probability that coin 1 lands on heads **and** coin 2 lands on heads.
We can assume that the coins do not affect each other in any way, so each coin flip is **independent** of the other (i.e., the outcome of coin 1 does not affect the outcome of coin 2, and *vice versa* -- this kind of assumption is often very important in statistics).
Each coin, by itself, is expected to to land on heads with a probability of 0.5, $P(heads) = 0.5$.
When we want to know the probability that two or more independent events will happen, we *multiply* their probabilities.
In the case of both coins landing on heads, the probability is therefore,

$$P(Coin_{1} = heads\:\cap Coin_{2} = heads) = 0.5 \times 0.5 = 0.25.$$

Note that the symbol $\cap$ is basically just a fancy way of writing 'and' (technically, the intersection between sets; see set theory for details).
Verbally, all this is saying is that the probability of coin 1 landing on heads *and* the probability of coin 2 landing on heads equals 0.5 times 0.5, which equals 0.25.

But why are we multiplying to get the joint probability of both coins landing on heads?
Why not add, for example?
Well, we could take it as a given that multiplication is the correct operation to use when calculating the probability that multiple events will occur.
We could also do a simple experiment to confirm that 0.25 really is about right (e.g., by flipping 2 coins 100 times and recording how many times both coins land on heads).
But neither of these would likely be particularly satisfying.
Let us first recognise that adding the probabilities cannot be the correct answer.
If the probability of each coin landing on heads is 0.5, the adding probabilities would imply that the probability of both landing on heads is 0.5 + 0.5 = 1.
This does not make any sense because we know that there are other possibilities, such as both coins landing on tails, or one coin landing on heads and the other landing on tails.
Adding probabilities cannot be the answer, but why multiply?

We can think about probabilities visually, as a kind of probability space.
When we have only one trial, then we can express the probability of an event along a line (Figure 14.1).

```{r, echo = FALSE, fig.alt = "A drawing of a line from 0 to 1 with heads indicated below 0.5 and tails indicated above 0.5.", fig.cap = "Total probability space for flipping a single coin and observing its outcome (heads or tails). Given a fair coin, the probability of heads equals a proportion 0.5 of the total probability space, while the probability of tails equals the remaining 0.5 proportion.", out.width="100%"}
knitr::include_graphics("img/coin1_probability.png");
```

The total probability space is 1, and 'heads' occupies a density of 0.5 of the total space.
The remaining space, also 0.5, is allocated to 'tails'.
If we add a second independent trial, we now need 2 dimensions of probability space (Figure 14.2).
The probability of heads or tails for coin 1 (the horizontal axis of Figure 14.2) remains unchanged, but we add another axis (vertical this time) to think about the equivalent probability space of coin 2.

```{r, echo = FALSE, fig.alt = "A square is shown with coin 1 probability on the bottom and coin 2 probability on the left side, with a cross in the centre of the square indicating a division between outcomes of coin flips (heads-heads, heads-tails, etc.).", fig.cap = "Total probability space for flipping two coins and observing their different possible outcomes (heads-heads, heads-tails, tails-heads, and tails-tails). Given two fair coins, the probability of flipping each equals 0.25, which corresponds to the lower left square of the probability space.", out.width="100%"}
knitr::include_graphics("img/coin2_probability.png");
```

Now we can see that that the area in which both coin 1 and coin 2 land on heads has a proportion of 0.25 of the total area.
This is a geometric representation of what we did when calculating $P(Coin_{1} = heads\:\cap Coin_{2} = heads) = 0.5 \times 0.5 = 0.25.$
The multiplication works because multiplying probabilities carves out more specific regions of probability space.
Note that the same pattern would apply if we flipped a third coin.
In this case, the probability of all 3 coins landing on heads would be $0.5 \times 0.5 \times 0.5 = 0.125$, or $0.5^{3} = 0.125$.

What about when we want to know the probability of one outcome **or** another outcome happening?
Here is where we add.
Note that the probability of a coin flip landing on heads or tails must be 1 (there are only 2 possibilities!).
What about the probability of both coins landing on the same outcome; that is, either both coins landing on heads or both landing on tails?
We know that the probability of both coins landing on heads is $0.25$.
The probability of both coins landing on tails is also $0.25$, so the probability that both coins land on either heads **or** tails is $0.25 + 0.25 = 0.5$.
The visual representation in Figure 14.2 works for this example too.
Note that heads-heads and tails-tails outcomes are represented by the lower left and upper right areas of probability space, respectively.
This is 0.5 (i.e., 50\%) of the total probability space.


## Biological applications

Coin flips are instructive, but the relevance for biological and environmental sciences might not be immediately clear.
In fact, probability is extremely relevant in nearly all areas of the natural sciences.
The following are just 2 hypothetical examples where the calculations in the previous section might be usefully applied:

1. From a recent report online, you learn that 1 in 40 people in your local area are testing positive for Covid-19. You find yourself in a small shop with 6 other people. What is the probability that at least 1 of these 6 other people would test positive for Covid-19? To calculate this, note that the probability that any given person has Covid-19 is $1/40 = 0.025$, which means that the probability that they do **not** must be $1 - 0.025 = 0.975$ (they either do or do not, and the probabilities must sum to 1). The probability that **all** 6 people *do not* have Covid-19 is therefore $(0.975)^6 = 0.859$. Consequently, the probability that at least 1 of the 6 people **does** have Covid-19 is $1 - 0.859 = 0.141$, or $14.1\%$. 

2. Imagine you are studying a population of sexually reproducing, diploid, animals, and you find that a particular genetic locus has 3 alleles with frequencies $P(A_{1}) = 0.40$, $P(A_{2}) = 0.45$, and $P(A_{3}) = 0.15$. What is the probability that a randomly sampled animal will be heterozygous with 1 copy of the $A_{1}$ allele and 1 copy of the $A_{3}$ allele? Note that there are two ways for $A_{1}$ and $A_{3}$ to be arise in an individual, just like there were two ways to get a heads and tails coin in the section 14.1 example (see Figure 14.2). The individual could either get an $A_{1}$ in the first position and $A_{3}$ in the second position, or an $A_{3}$ in the first position and $A_{1}$ in the second position. We can therefore calculate the probability as, $P(A_{1}) \times P(A_{3}) + P(A_{3}) \times P(A_{1})$, which is $(0.40 \times 0.15) + (0.15 \times 0.4) = 0.12$, or 12\% (in population genetics, we might use the notation $p = P(A_{1})$ and $r = P(A_{3})$, then note that $2pr = 0.12$).

In both of these examples, we made some assumptions, which might or might not be problematic.
In the first example, we assumed that the 6 people in our shop were a random and independent sample from the local area (i.e., people with Covid-19 are not more or less likely to be in the shop, and the 6 people in the shop were not associated in a way that would affect their individual probabilities of having Covid-19).
In the second example, we assumed that individuals mate randomly, and that there is no mutation, migration, or selection on genotypes [@Hardy1908].
It is important to recognise these assumptions when we are making them, as violations of assumptions could affect the probabilities of events!


## Sampling with and without replacement

It is often important to make a distinction between sampling with or without replacement.
Sampling with replacement just means that whatever has been sampled once gets put back into the population before sampling again.
Sampling without replacement means that the whatever has been sampled does not get put back into the population.
An example makes the distinction between sampling with and without replacement clearer.

```{r, echo = FALSE, fig.alt = "Close up of 10 playing cards are shown, 5 hearts (left) and 5 clubs (right). Cards decrease from 5 to ace left to right for both suits.", fig.cap = "Playing cards can be useful for illustrating concepts in probability. Here we have 5 hearts (left) and 5 clubs (right).", out.width="100%"}
knitr::include_graphics("img/cards.jpg");
```

Figure 14.3 shows 10 playing cards, 5 hearts and 5 clubs.
If we shuffle these cards thoroughly and randomly select 1 card, what is the probability of selecting a heart?
This is simply,

$$P(heart) = \frac{5\:hearts}{10\:total\:cards} = 0.5.$$

What is the probability randomly selecting two hearts?
This depends if we are sampling with or without replacement.
If we sample 1 card, then put it back into the deck before sampling the second card, then the probability of sampling a heart does not change (in both samples, we have 5 hearts and 10 cards).
Hence, the probability of sampling two hearts with replacement is $P(heart) \times P(heart) = 0.5 \times 0.5 = 0.25$.
We do not put the first card back into the deck before sampling again, then we have changed the total number of cards.
After sampling the first heart, we have one fewer hearts in the deck and one fewer cards, so the new probability for sampling a heart becomes,

$$P(heart) = \frac{4\:hearts}{9\:total\:cards} = 0.444.$$

Since the probability has changed after the first heart is sampled, we need to use this adjusted probability when sampling without replacement.
In this case, the probability of sampling two hearts is $0.5 \times 0.444 = 0.222$.
This is a bit lower than the probability of sampling with replacement because we have decreased the number of hearts that can be sampled.
When sampling from a set, it is important to consider whether the sampling is done with or without replacement (in assessments, we will always make this clear).


## Probability distributions

Up until this point, we have been considering the probabilities of specific outcomes.
That is, we have considered the probability that a coin flip will be heads, that an animal will have a particular combination of alleles, or that we will randomly select a particular suit of card from a deck.
Here we will move from specific outcomes and consider the *distribution* of outcomes.
For example, instead of finding the probability that a flipped coin lands on heads, we might want to consider the distribution of the number of times that it does (in this case, 0 times or 1 time).

```{r, echo = FALSE, fig.alt = "A barplot is shown with 2 bars, one labelled 0 and one labelled 1, both of which are the same height (0.5). The x-axis is labelled 'Times coin flip is heads'.", fig.cap = "Probability distribution for the number of times that a flipped coin lands on heads in 1 trial."}
par(mar = c(5, 5, 1.5, 1.5));
plot(x = 0, y = 0, xlim = c(0.5, 2.5), type = "n", ylim = c(0, 1), xaxt = "n",
     ylab = "Probability", xlab = "Times a coin flip is heads", cex.lab = 1.25,
     cex.axis = 1.25, yaxs = "i");
axis(side = 1, at = 1:2, labels = 0:1);
yy <- seq(from = 0, to = 0.5, length = 100);
points(x = rep(1, times = 100), y = yy, type = "l", lwd = 6);
points(x = rep(2, times = 100), y = yy, type = "l", lwd = 6);
```

This is an extremely simple distribution.
There are only two discrete possibilities for the number of times the coin will land on heads, 0 or 1.
And the probability of both outcomes is 0.5, so the bars in Figure 14.4 are the same height.
Next, we will consider some more interesting distributions.


### Binomial distribution

The simple distribution with a single trial of a coin flip was actually an example of a binomial distribution.
More generally, a binomial distribution describes the number of successes in some number of trials [@Miller2004].
The word 'success' should not be taken too literally here; it does not necessarily indicate a good outcome, or an accomplishment of some kind.
A success in the context of a binomial distribution just means that an outcome *did* happen as opposed to it *not* happening.
If we define a coin flip landing on heads as a success, we could consider the probability distribution of the number of success over 10 trials (Figure 14.5)

```{r, echo = FALSE, fig.alt = "A barplot is shown with 11 bars, which correspond to the number of times a coin flip lands on heads; the distribution takes a humped shape", fig.cap = "Probability distribution for the number of times that a flipped coin lands on heads in 10 trials."}
par(mar = c(5, 5, 1.5, 1.5));
pr_binom <- dbinom(x = 0:10, size = 10, prob = 0.5);
plot(x = 0, y = 0, xlim = c(0.5, 11.5), type = "n", ylim = c(0, 0.3), 
     xaxt = "n", ylab = "Probability", xlab = "Times a coin flip is heads", 
     cex.lab = 1.25, cex.axis = 1.25, yaxs = "i");
axis(side = 1, at = 1:11, labels = 0:10);
for(i in 1:11){
  yy <- seq(from = 0, to = pr_binom[i], length = 100);
  points(x = rep(i, times = 100), y = yy, type = "l", lwd = 6);  
}
```

Figure 14.5 shows that the most probable outcome is that 5 of the 10 coins flipped will land on heads.
This makes some sense because the probability that any 1 flip lands on heads is 0.5, and 5 is 1/2 of 10.
But 5 out 10 heads happens only with a probability of about 0.25.
There is also about a 0.2 probability that the outcome is 4 heads, and the same probability that the outcome is 6 heads.
Hence, the probability that we get an outcome of between 4-6 heads is about $0.25 + 0.2 + 0.2 = 0.65$.
In contrast, the probability of getting all heads is very low (about 0.00098).

More generally, we can define the number of successes using the random variable $X$.
We can then use the notation $P(X = 5) = 0.25$ to indicate the probability of 5 successes, or $P(4 \leq X \leq 6) = 0.65$ as the probability that the number of success being greater than or equal to 4 and less than or equal to 6.

Imagine that you were told a coin was fair, then flipped it 10 times.
Imagine that 9 flips out of the 10 came up heads.
Given the probability distribution shown in Figure 14.5, the probability of getting 9 or more heads in 10 flips given a fair coin is very low ($P(X \geq 9) \approx 0.011$).
Would you still believe that the coin is fair after these 10 trials?
How many, or how few, heads would it take to convince you that the coin was not fair?
This question gets to the heart of a lot of hypothesis-testing in statistics, and we will discuss it more in Week 6. 

Note that a binomial distribution does not need to involve a fair coin with equal probability of success and failure.
We can consider again the first example in Section 14.2, in which 1 in 40 people in an area are testing positive for Covid-19, then ask what the probability is that 0-6 people in a small shop would test positive (Figure 14.6).

```{r, echo = FALSE, fig.alt = "A barplot is shown with 7 bars, which correspond to the probability that a given number of people have covid in a shop of 6 when the probability of infection is 0.025.", fig.cap = "Probability distribution for the number of people who have Covid-19 in a shop of 6 when the probability of testing positive is 0.025."}
par(mar = c(5, 5, 1.5, 1.5));
pr_binom <- dbinom(x = 0:6, size = 10, prob = 1/40);
plot(x = 0, y = 0, xlim = c(0.5, 7.5), type = "n", ylim = c(0, 1), 
     xaxt = "n", ylab = "Probability", xlab = "People testing positive", 
     cex.lab = 1.25, cex.axis = 1.25, yaxs = "i");
axis(side = 1, at = 1:11, labels = 0:10);
for(i in 1:7){
  yy <- seq(from = 0, to = pr_binom[i], length = 100);
  points(x = rep(i, times = 100), y = yy, type = "l", lwd = 6);  
}
```

Note that the shape of this binomial distribution is different from the coin flipping trials in Figure 14.7.
The distribution is skewed, with a high probability of 0 success and a diminishing probability of 1 or more success.[^13]

[^13]: Testing an equation $$y = mx + b.$$ Does this get produced inline or not?


### Poisson distribution

Another example

### Uniform distribution



### Normal distribution

Why this is so important


# The Central Limit Theorem (CLT)

General overview

## Examples of the CLT in action

## The standard normal distribution

## What are z-scores?


# _Practical_. Probability and simulation

This practical focuses on applying the concepts from chapter 14 and 15 in Jamovi.
There will be 3 exercises.

1. Calculating probabilities from a dataset.
2. Calculating probabilities from a normal distribution.
3. Demonstrating the central limit theorem (CLT).

To complete exercises 2 and 3, we will need to download and install two new Jamovi modules.
Jamovi Modules are add-ons that make it possible to run specialised statistical tools inside Jamovi.
These tools are written by a community of statisticians, scientists, and educators and listed in the [Jamovi library](https://www.jamovi.org/library.html).
Like Jamovi, these tools are open source and free to use.

The dataset for this practical is something a bit different.
It comes from the [Beacon Project](https://www.thebeaconproject.net/), which is an interdisciplinary scientific research programme led by [Dr Isabel Jones](https://www.stir.ac.uk/people/256518) at the University of Stirling.
This project focuses on large hydropower dams as a way to understand the trade-offs between different United Nations [Sustainable Development Goals](https://sdgs.un.org/goals).
It addresses challenging questions about environmental justice, biodiversity, and sustainable development.  
The project works with people affected, and sometimes displaced, by dam construction in Brazil, Kazakhstan, India, USA, and the UK.
Part of this project involves the use of mobile games to investigate how people make decisions about sustainable development.

```{r, echo = FALSE, fig.alt = "Decorative image shown of the interface of the mobile app game Power Up!", fig.cap = "Welcome screen of the mobile game Power Up!", out.width="80%"}
knitr::include_graphics("img/power_up.png")
```

The game "Power Up!" is freely available as an [Android](https://play.google.com/store/apps/details?id=com.hyperluminal.stirlinguniversity.sustainabledevelopmentgame) and [iPhone](https://apps.apple.com/gb/app/power-up/id1585634888) app (Figure 16.1).
Data are collected from players' decisions and used to investigate social-ecological questions.
We will use the [power_up](https://raw.githubusercontent.com/bradduthie/statistical_techniques/main/data/power_up.csv) dataset in exercises 1 and 2.
To get started, first download the [power_up](https://raw.githubusercontent.com/bradduthie/statistical_techniques/main/data/power_up.csv) dataset and open them in Jamovi.
Note that these data are already in a tidy format, so we do not need to do any reorganising.
The dataset includes columns for each player's ID, the OS that they use, the dam size that they decided to build in the game, their in-game investment in Biodiversity, Community, and Energy, and their final Score.


## Probabilities from a dataset

Suppose that we want to estimate the probability that a new Power Up! game player will be an Android user.
To estimate this probability, we can use the proportion of players in the dataset who are Android users.
To get this proportion, we need to divide the number of Android users by the total number of players,

$$P_{(Android)} = \frac{Number\:of\:Android\:users}{Number\:of\:players}.$$

In Jamovi, you could figure this out the long way by counting up the number of rows with 'Android' in the second column, then dividing by the total number of rows.
But there is an easier way, which is faster and less prone to human error than manually tallying up items.
To do this, go to the Analyses tab in Jamovi and navigate to Exploration, then Descriptives.
Place the 'OS' variable in to the 'Variables' box.
Next, find the check box called 'Frequency tables' just under the 'Split by' box and above the 'Statistics' drop down tab.
Check this box to get a table of frequencies for Android versus iPhone users.

```{r, echo = FALSE, fig.alt = "Jamovi interface of Descriptives with OS selected as a Variable and a frequency table to the right showing the frequencies of Android and iPhone users", fig.cap = "Jamovi Descriptives toolbar showing the OS column from the Power Up! dataset selected. The 'Frequency tables' checkbox builds a table of counts and percentages.", out.width="100%"}
power_up  <- read.csv("data/power_up.csv");
android_N <- sum(power_up$OS == "Android");
iPhone_N  <- sum(power_up$OS == "iPhone");
knitr::include_graphics("img/jamovi_power_up_frequencies.png")
```

The table of frequencies shown in Figure 16.2 includes counts of Android versus iPhone users.
We can see that `r android_N` of the `r dim(power_up)[1]` total game players use Android, while `r iPhone_N` players use iPhone.
To get the proportion of Android users we could divide `r android_N` by `r dim(power_up)[1]` to get `r android_N/dim(power_up)[1]`.
Similarly, the proportion of iPhone users, we could calculate `r iPhone_N` / `r dim(power_up)[1]` = `r iPhone_N/dim(power_up)[1]`.
But Jamovi already does that for us, with a bit of rounding.
The second column of the Frequencies table gives us these proportions, but expressed as a percentage.
The percentage of Android users is `r round(100 * android_N/dim(power_up)[1], digits = 1)`%, and the percentage of iPhone users is `r round(100 * iPhone_N/dim(power_up)[1], digits = 1)`%.
Percentages are out of a total of 100, so to get back to the proportions, we can just divide by 100, `r round(100 * android_N/dim(power_up)[1], digits = 1)` / 100 = `r round(100 * android_N/dim(power_up)[1], digits = 1)/100` for Android and `r round(100 * iPhone_N/dim(power_up)[1], digits = 1)` / 100 = `r round(100 * iPhone_N/dim(power_up)[1], digits = 1)/100` for iPhone.
To answer the original question, our best estimate of the probability that a new Power Up! game player will be an Android user is therefore `r round(android_N/dim(power_up)[1], digits = 3)`.

Next, use the same procedure to find the probability that a game player will make a small, medium, and large size dam.
Now, fill in Table 16.1 with counts, percentage, and the estimated probability of a player selecting a small, medium, or large dam.

| Dam size  |  Counts  |  Percentage |  Estimated Probability |
|-----------|----------|-------------|------------------------|
| Small     |          |             |                        |
| Medium    |          |             |                        |
| Large     |          |             |                        |

Table: Statistics of Power Up! decisions for dam size.

We can use these estimated probabilities of small, medium, and large dam size selection to predict what will happen in future games.
Suppose that a new player decides to play the game.
What is the probability that this player chooses a small **or** a large dam?

$Pr_{(small\:or\:large)} =$ : __________________________

Now suppose that 3 new players arrive and decide to play the game.
What is the probability that all 3 of these new players choose a large dam?

$Pr_{(3\:large)} =$ : __________________________

What is the probability that all 3 of these new players choose *different* dam sizes?

$Pr_{(small,\:medium,\:large)} =$ : __________________________

Now consider a slightly different type of question.
Instead of trying to predict the probability of new player decisions, we will focus on sampling from the existing power up dataset.
Imagine that you randomly choose one of the `r dim(power_up)[1]` players with equal probability (i.e., every player is equally likely to be chosen).
What is the probability that you choose player 20?

$Pr_{(Player\:20)} =$ : __________________________

What is the probability that you choose player 20, *then* choose a different player with a large dam?
As a hint, remember that you are now sampling *without replacement*. 
The second choice cannot be player 20 again, so the probability of choosing a player with a large dam has changed from the estimated probability in Table 16.1.

$Pr_{(Player\:20,\:Large)} =$ : __________________________

Now we can use the Descriptives tool in Jamovi to ask a slightly different question with the data.
Suppose that we wanted to estimate the probability that an Android user will choose a large dam.
We could multiply the proportion of Android users times the proportion of players who choose a large dam (i.e., find the probability of Android *and* large dam).
But this assumes that the two characteristics are independent (i.e., that Android users are not more or less likely than iPhone users to build large dams).
To estimate the probability that a player chooses a large dam *given* that they are using Android, we can keep Dam_size in the Variables box, but now put OS in the 'Split by' box.
Figure 16.3 shows the output of Jamovi.
A new frequency table breaks down dam choice for each OS.

```{r, echo = FALSE, fig.alt = "Jamovi interface of Descriptives with dam size selected as a Variable split by OS, and a frequency table to the right showing the frequencies of Android and iPhone users who chose small, medium, and large dams.", fig.cap = "Jamovi Descriptives toolbar showing the dam size column from the Power Up! dataset selected as a variable split by OS. The 'Frequency tables' checkbox builds a table of counts for small, medium, and large dam size broken down by Android versus iPhone OS.", out.width="100%"}
knitr::include_graphics("img/jamovi_power_up_frequencies2.png")
```


To get the proportion of Android users who choose to build a large dam, we just need to divide the number of Android users who chose the large dam size by the total number of Android users (i.e., sum of the first column in the Frequencies table; Figure 16.3).

$$P_{(Large | Android)} = \frac{Number\:of\:Android\:users\:choosing\:large\:dam}{Number\:of\:Android\:users}.$$

Now, recreate the table in Figure 16.3 and estimate the probability that an Android user will choose to build a large dam,

$P_{(Large | Android)} =$ : __________________________

Is $P_{(Large | Android)}$ much different from the probability that *any* player chooses a large dam, as calculated in Table 16.1? Do you think that the difference is significant?


```








```

Next, we will move on to calculating probabilities from a normal distribution.


## Probabilities from a normal distribution

In the example of the first exercise, we looked at OS and dam size choice.
Players only use Android or iPhone, and they could only choose one of three sizes of dam.
For these nominal variables, estimating the probability of a particular discrete outcome (e.g., Android versus iPhone) was just a matter of dividing counts.
But we cannot use the same approach for calculating probabilities from continuous data.
Consider, for example, the final score for each player in the column 'Score'.
Because of how the game was designed, Score can potentially be any real number, although most scores are somewhere around 100.
We can use a histogram to see the distribution of player scores (Figure 16.4).

```{r, echo = FALSE, fig.alt = "A histogram is shown with a normal shape. The x-axis is labelled 'Player Score'.", fig.cap = "Distribution of player scores in the game Power Up!", out.width="100%"}
hist(x = power_up$Score, xlab = "Player Score", cex.lab = 1.25, cex.axis = 1.25,
     main = "", freq = FALSE);
```

In this case, it does not really make sense to ask what the probability is of a particular score.
If the score can take *any* real value, out to as many decimals as we want, then what is the probability of a score being *exactly* 94.97 (i.e., 94.97 with infinite zeros after it, $94.9700000\bar{0}$)?
The probability is infinitesimal, i.e., basically zero, because there are an infinite number of real numbers.
Consequently, we are not really interested in the probabilities of specific values of continuous data.
Instead, we want to focus on intervals.
For example, what is the probability that a player scores higher than 120?
What is the probability that a player scores lower than 100?
What is the probability that a player scores between 120 and 100?

Take another look at Figure 16.4 above, then take a guess at each of these probabilities.
As a hint, the y-axis of this histogram is showing density instead of frequency.
What this means is that the total grey area (i.e., the histogram bars) sums to 1.
Guessing the probability that a player scores higher than 120 is the same as guessing the proportion of grey space in the highest 4 bars of Figure 16.4 (i.e., grey space >120).

$P_{(Score>120)} =$ : __________________________

$P_{(Score<100)} =$ : __________________________


$P_{(100<Score<120)} =$ : __________________________

Trying to do this by looking at a histogram is not easy, and it is really not the best way to get the above probabilities.
We can get much better estimates using Jamovi, but we need to make an assumption about the distribution of Player Score.
Specifically, we need to assume that the distribution of Player Score has a specific shape.
More technically, we must assume a specific probability density function that we can use to mathematically calculate probabilities of different ranges of player scores.
Inspecting Figure 16.4, Player Score appears to be normally distributed.
In other words, the shape of Player Score distribution appears to be normal, or 'Gaussian'.
If we are willing to assume this, then we can calculate probabilities using its mean and standard deviation.
Use Jamovi to find the mean and the standard deviation of player score (note, we can just say that score is unitless, so no need to include units).

Mean score: __________________________

Standard deviation score: __________________________

We will assume that the *sample* of scores shown in Figure 16.4 came from a *population* that is normally distributed with the mean and standard deviation above that you wrote above (recall sample versus population from [Chapter 4](#Chapter_4)).
We can overlay his distribution on the histogram above using a curved line (Figure 16.5).

```{r, echo = FALSE, fig.alt = "A histogram is shown with a normal shape. The x-axis is labelled 'Player Score', and there is a line indicating the probability density function of a normal distribution overlaid.", fig.cap = "Distribution of player scores in the game Power Up! shown in histogram bars. The overlaid curve shows the probability density function for a normal distribution that has the same mean and standard deviation as the sample described by the histogram.", out.width="100%"}
hist(x = power_up$Score, xlab = "Player Score", cex.lab = 1.25, cex.axis = 1.25,
     main = "", freq = FALSE);
mnsc <- mean(power_up$Score);
sdsc <- sd(power_up$Score);
xx   <- seq(from = 30, to = 180, by = 0.001);
d_yy <- dnorm(x = xx, mean = mnsc, sd = sdsc);
points(x = xx, y = d_yy, type = "l", lwd = 3);
```


We can interpret the area under the curve in the same way that we interpret the area in the grey bars. 
As mentioned earlier, the total area of the histogram bars must sum to 1.
The total area under the curve must also sum to 1.
Both represent the probability of different ranges of player scores.
Notice that the normal distribution is not a perfect match for the histogram bars.
For example, the middle bar of values illustrating scores between 90 and 100 appears to be a bit low compared to a perfect normal distribution, and there are more scores between 40 and 50 than we might expect.
Nevertheless, the two distributions broadly overlap, so we might be willing to assume that the player scores represented in the histogram bars are sampled from the population described by the curve.

Because the curve relating player score to probability density is described by an equation (see [Chapter 14](#Chapter_14)), we can use that equation to make inferences about the probabilities of different ranges of scores.
The simplest example is the mean of the distribution.
Because the normal distribution is symmetric, the area to the left of the mean must be the same as the area to the right of the mean.
And since the whole area under the curve must sum to 1, we can conclude that the probability of sampling a player score that is less than the mean is 1/2, and the probability of sampling a player score greater than the mean is also 1/2.
Traditionally, we would need to do some maths to get other player score probabilities, but Jamovi can do this much more easily.

To get Jamovi to calculate probabilities from a normal distribution, we need to go to the Modules option and download a new module (Figure 16.5).


```{r, echo = FALSE, fig.alt = "Jamovi toolbar is shown, which includes an option on the far right hand side called 'modules'.", fig.cap = "Jamovi tool bar, which includes an option for downloading new Modules (right hand side)", out.width="100%"}
knitr::include_graphics("img/jamovi_toolbar_modules.png")
```

Click on the 'Modules' button, and select the first option called 'jamovi library' from the pull-down menu.
From the 'Available' tab, scroll down until you find the Module called 'distrACTION - Quantiles and Probabilities of Continuous and Discrete Distributions' [@Rihs2018].
Click the 'Install' button to install it into Jamovi.
A new button in the toolbar called 'distrACTION' should become visible (Figure 16.6).

```{r, echo = FALSE, fig.alt = "Jamovi toolbar is shown, which includes an option on the far right hand side called 'modules' and a button called distrACTION.", fig.cap = "Jamovi tool bar, which includes an added module called distrACTION.", out.width="100%"}
knitr::include_graphics("img/jamovi_toolbar_modules_distrACTION.png")
```

If the module is not there, then it should be possible to find by again going to Modules and selecting distrACTION from the pulldown menu.
Click on the module and choose 'Normal Distribution' from the pulldown menu.
Next, we can see a box for the mean and standard deviation (SD) under the 'Parameters' subtitle in bold.
Put the mean and the standard deviation calculated from above into these boxes.
In the panel on the right, Jamovi will produce the same normal distribution that is in Figure 16.5 (note that the axes might be scaled a bit differently).

Given this normal distribution, we can compute the probability that a player scores less than x1 = 80 by checking the box 'Compute probability', which is located just under 'Function' (Figure 16.8).
We can then select the first radio button to find the probability that a randomly sampled value X from this distribution is less than x1, $P(X \leq x1)$.
Notice in the panel on the right that the probability is given as $P =$ `r round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)`.
This is also represented in the plot of the normal distribution, with the same proportion in the lower part of the distribution shaded ($P =$ `r round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)`, i.e., ca `r round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3) * 100` per cent).

```{r, echo = FALSE, fig.alt = "Jamovi options for a module that calculates probabilities associated with a normal distribution, with computing probability checkboxes and radio buttons selected", fig.cap = "Jamovi options for the distrACTION module for computing probability for a given normal distribution. The example shown here calculates the probability that a value sampled from the normal distribution of interest is less than 80.", out.width="80%"}
knitr::include_graphics("img/jamovi_normal_distribution.png")
```

To find the probability that a value is greater than 80, we could subtract our answer of `r round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)` from 1, $1 - `r round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)` = `r 1 - round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)`$ (remember that the total area under the normal curve equals 1, so the shaded plus the unshaded region must also equal 1; hence, 1 minus the shaded region gives us the unshaded region).
We could also just select the second radio button for $P(X \geq x1)$.
Give this a try, and notice that the shaded and unshaded regions have flipped in the plot, and we get our answer in the table of $P =$ `r 1 - round(pnorm(q = 80, mean = mean(power_up$Score), sd = sd(power_up$Score)), digits = 3)`.

Finally, to compute the probability of an interval, we can check the third radio button and set x2 in the bottom box (Figure 16.8). 
For example, to see the probability of a score between 80 and 120, we can choose select $P(x1 \leq X \leq x2)$, then setting x2 = 120 in the bottom box.
Notice where the shaded area is in the newly drawn plot.
What is the probability of a player getting a score between 80 and 120?

$P(80 \leq X \leq 120)$ = : __________________________

What is the probability of a player getting a score greater than 130?

$P(X \geq 130)$ = : __________________________

Now try the following probabilities for different scores.

$P(X \geq 120)$ = : __________________________


$P(X \leq 100)$ = : __________________________


$P(100 \leq X \leq 120)$ = : __________________________

Note, these last three were the same intervals that you guessed using the histogram. 
How close was your original guess to the calculations above?

```








```


One last one.
What is the probability of a player getting a score lower than 70 or higher than 130?

$P(X \leq 70 \: | \: X \geq 130)$ = : __________________________

There is more than one way to figure this last one out.
How did you do it, and what was your reasoning?


```








```


We will now move on to the central limit theorem.


## Central limit theorem


To demonstrate the central limit theorem, we need to download and install another module in Jamovi.
This time, go to 'Modules', and from the 'Available' tab, scroll down until you find 'Rj' in the Jamovi library.
Install 'Rj', then a new button 'R' should become available in the toolbar.
This will allow us to run a bit of script using the coding language R.
We will work with R a bit more in future practicals, but for now you will not need to do anymore than copying and pasting code.
For now, click on the new 'R' button in the toolbar and select 'Rj Editor' from the pulldown menu.
You will see an open editor; this is where the code will go.
If it has some code in it already (e.g., `# summary(data[1:3])`), just delete it so that we can start with a clean slate.
Copy and paste the following lines into the Rjeditor.


```{r, eval = FALSE}
v1  <- runif(n = 200, min = 0, max = 100);
v2  <- runif(n = 200, min = 0, max = 100);
v3  <- runif(n = 200, min = 0, max = 100);
v4  <- runif(n = 200, min = 0, max = 100);
v5  <- runif(n = 200, min = 0, max = 100);
v6  <- runif(n = 200, min = 0, max = 100);
v7  <- runif(n = 200, min = 0, max = 100);
v8  <- runif(n = 200, min = 0, max = 100);
v9  <- runif(n = 200, min = 0, max = 100);
v10 <- runif(n = 200, min = 0, max = 100);
v11 <- runif(n = 200, min = 0, max = 100);
v12 <- runif(n = 200, min = 0, max = 100);
v13 <- runif(n = 200, min = 0, max = 100);
v14 <- runif(n = 200, min = 0, max = 100);
v15 <- runif(n = 200, min = 0, max = 100);
v16 <- runif(n = 200, min = 0, max = 100);
v17 <- runif(n = 200, min = 0, max = 100);
v18 <- runif(n = 200, min = 0, max = 100);
v19 <- runif(n = 200, min = 0, max = 100);
v20 <- runif(n = 200, min = 0, max = 100);
v21 <- runif(n = 200, min = 0, max = 100);
v22 <- runif(n = 200, min = 0, max = 100);
v23 <- runif(n = 200, min = 0, max = 100);
v24 <- runif(n = 200, min = 0, max = 100);
v25 <- runif(n = 200, min = 0, max = 100);
v26 <- runif(n = 200, min = 0, max = 100);
v27 <- runif(n = 200, min = 0, max = 100);
v28 <- runif(n = 200, min = 0, max = 100);
v29 <- runif(n = 200, min = 0, max = 100);
v30 <- runif(n = 200, min = 0, max = 100);
v31 <- runif(n = 200, min = 0, max = 100);
v32 <- runif(n = 200, min = 0, max = 100);
v33 <- runif(n = 200, min = 0, max = 100);
v34 <- runif(n = 200, min = 0, max = 100);
v35 <- runif(n = 200, min = 0, max = 100);
v36 <- runif(n = 200, min = 0, max = 100);
v37 <- runif(n = 200, min = 0, max = 100);
v38 <- runif(n = 200, min = 0, max = 100);
v39 <- runif(n = 200, min = 0, max = 100);
v40 <- runif(n = 200, min = 0, max = 100);

hist(x = v1, main = "", xlab = "Random uniform variable");
```


What this code is doing is creating 40 different datasets of 200 random numbers from 0 to 100 (there is a way to do all of this in much fewer lines of code, but it requires a bit more advanced use of R).
The `hist` function plots a histogram of the first variable.
To run the code, find the green triangle in the upper right (Figure 16.9).

```{r, echo = FALSE, fig.alt = "Jamovi window with an R editor open and several lines of code for generating uniform numbers.", fig.cap = "Jamovi interface for the Rj Editor module. Code can be run by clicking on the green triangle in the upper left.", out.width="80%"}
knitr::include_graphics("img/jamovi_RjEditor.png")
```


When you run the code, the 40 new variables will be created, each variable being made up of 200 random numbers.
The histogram for `v1` is plotted to the right (to plot other variables, substitute `v1` in the `hist` function for some other variable).
How would you describe the shape of the distribution of `v1`?

```








```


Next, we are going to get the mean value of each of the 40 variables. 
To do this, copy the code below and paste it at the bottom of the Rj Editor (somewhere below the `hist` function).

```{r, eval = FALSE}
m1  <- mean(v1);
m2  <- mean(v2);
m3  <- mean(v3);
m4  <- mean(v4);
m5  <- mean(v5);
m6  <- mean(v6);
m7  <- mean(v7);
m8  <- mean(v8);
m9  <- mean(v9);
m10 <- mean(v10);
m11 <- mean(v11);
m12 <- mean(v12);
m13 <- mean(v13);
m14 <- mean(v14);
m15 <- mean(v15);
m16 <- mean(v16);
m17 <- mean(v17);
m18 <- mean(v18);
m19 <- mean(v19);
m20 <- mean(v20);
m21 <- mean(v21);
m22 <- mean(v22);
m23 <- mean(v23);
m24 <- mean(v24);
m25 <- mean(v25);
m26 <- mean(v26);
m27 <- mean(v27);
m28 <- mean(v28);
m29 <- mean(v29);
m30 <- mean(v30);
m31 <- mean(v31);
m32 <- mean(v32);
m33 <- mean(v33);
m34 <- mean(v34);
m35 <- mean(v35);
m36 <- mean(v36);
m37 <- mean(v37);
m38 <- mean(v38);
m39 <- mean(v39);
m40 <- mean(v40);

all_means <- c(m1,  m2,  m3,  m4,  m5,  m6,  m7,  m8,  m9,  m10, 
               m11, m12, m13, m14, m15, m16, m17, m18, m19, m20,
               m21, m22, m23, m24, m25, m26, m27, m28, m29, m30,
               m31, m32, m33, m34, m35, m36, m37, m38, m39, m40);
```


Now we have calculated the mean for each variable.
The last line of code defines `all_means`, which makes a new dataset that includes the mean value of each of our original variables.
Think about what you think the distribution of these mean values will look like. 
Sketch what you predict the shape of its distribution will be below.

```








```


Now, add one more line of code to the very bottom of the Rj Editor.


```{r, eval = FALSE}
hist(x = all_means, main = "", xlab = "All variable means");
```

This last line will make a histogram of the means of all 40 variables.
Click the green button again to run the code.
Compare the distribution of the original `v1` to the means of variables 1-40, and to your prediction above.
Is this what you expected?
As best you can, explain why the shapes of the two distributions differ.


```








```

We did all of this the long way to make it easier to see and think about the relationship between the original, uniformly distributed, variables and the distribution of their means.
Now, we can repeat this more quickly using one more Jamovi module.
Go to 'Modules', and from the 'Available' tab, download the 'clt - Demonstrations' module from the Jamovi library.
Once it is downloaded, go to the 'Demonstrations' button in the Jamovi toolbar and select 'Central Limit Theorem' from the pulldown menu.


```{r, echo = FALSE, fig.alt = "Jamovi window with the central limit theorem (CLT) module open and boxes for changing the distribution, sample size, and trial number", fig.cap = "Jamovi interface for the 'Demonstrations' module, which allows users to randomly generate data from a specific source distribution (normal, uniform, geometric, lognormal, and binary), sample size, and number of trials (i.e., variables)", out.width="80%"}
knitr::include_graphics("img/jamovi_clt.png")
```


To replicate what we did in the Rjeditor above, we just need to set the 'Source distribution' to 'uniform' using the pulldown menu, set the sample size to 200, and set the number of trials to 40 (Figure 16.10).
Try doing this, then look at the histogram generated to the lower right.
It should look similar, but not identical, to the histogram produced with the R code.
Now try increasing the number of trials to 200. 
What happens to the histogram?
What about when you increase the number of trials to 2000?


```








```

Try playing around with different source distributions, sample sizes, and numbers of trials.
What general conclusion can you make about the distribution of sample means from the different distributions?

```








```








