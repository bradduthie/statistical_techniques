@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.name/knitr/},
}
@book{Sokal1995,
address = {New York},
author = {Sokal, Robert R and Rohlf, F James},
edition = {3rd},
pages = {887},
publisher = {W. H. Freeman and Company},
title = {{Biometry}},
year = {1995}
}
@book{Dytham2011,
author = {Dytham, Calvin},
pages = {298},
publisher = {John Wiley \& Sons},
title = {{Choosing and Using Statistics: A Biologist's Guide}},
year = {2011}
}
@book{Spiegelhalter2019,
author = {Spiegelhalter, David},
pages = {426},
publisher = {Penguin UK},
title = {{The Art of Statistics Learning from Data}},
year = {2019}
}
@book{Box1978,
address = {New York},
author = {Box, G E P and Hunter, W G and S, Hunter J},
publisher = {John Wiley \& Sons},
title = {{Statistics for Experimenters: An Introduction to Design, Data Analysis, and Model Building}},
year = {1978}
}
@book{Navarro2022,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Navarro, Danielle J and Foxcroft, David R},
booktitle = {Learning Statistics with Jamovi: A Tutorial for Psychology Students and Other Beginners},
doi = {10.24384/hgc3-7p15},
file = {:home/brad/Dropbox/papers/Navarro_Foxcroft2022.pdf:pdf},
isbn = {9780333227794},
pages = {1--583},
publisher = {(Version 0.75)},
title = {{Learning Statistics with Jamovi}},
year = {2022}
}
@book{Rowntree2018,
author = {Rowntree, Derek},
pages = {199},
publisher = {Penguin},
title = {{Statistics Without Tears}},
year = {2018}
}
@article{Santin2016,
abstract = {The production of pyrogenic carbon (PyC; a continuum of organic carbon (C) ranging from partially charred biomass and charcoal to soot) is a widely acknowledged C sink, with the latest estimates indicating that $\sim$50% of the PyC produced by vegetation fires potentially sequesters C over centuries. Nevertheless, the quantitative importance of PyC in the global C balance remains contentious, and therefore, PyC is rarely considered in global C cycle and climate studies. Here we examine the robustness of existing evidence and identify the main research gaps in the production, fluxes and fate of PyC from vegetation fires. Much of the previous work on PyC production has focused on selected components of total PyC generated in vegetation fires, likely leading to underestimates. We suggest that global PyC production could be in the range of 116-385 Tg C yr-1, that is $\sim$0.2-0.6% of the annual terrestrial net primary production. According to our estimations, atmospheric emissions of soot/black C might be a smaller fraction of total PyC (<2%) than previously reported. Research on the fate of PyC in the environment has mainly focused on its degradation pathways, and its accumulation and resilience either in situ (surface soils) or in ultimate sinks (marine sediments). Off-site transport, transformation and PyC storage in intermediate pools are often overlooked, which could explain the fate of a substantial fraction of the PyC mobilized annually. We propose new research directions addressing gaps in the global PyC cycle to fully understand the importance of the products of burning in global C cycle dynamics.},
author = {Sant{\'{i}}n, Cristina and Doerr, Stefan H. and Kane, Evan S. and Masiello, Caroline A. and Ohlson, Mikael and de la Rosa, Jose Maria and Preston, Caroline M. and Dittmar, Thorsten},
doi = {10.1111/gcb.12985},
file = {:home/brad/Dropbox/papers/SantinEtAl2016.pdf:pdf},
issn = {13652486},
journal = {Global Change Biology},
keywords = {Biochar,Black carbon,Carbon accounting,Carbon emissions,Carbon sequestration,Charcoal,Dissolved organic carbon,Erosion,Pyrogenic organic matter,Wildfire},
number = {1},
pages = {76--91},
pmid = {26010729},
title = {{Towards a global assessment of pyrogenic carbon from vegetation fires}},
volume = {22},
year = {2016}
}
@article{Preston2006,
abstract = {The carbon (C) cycle in boreal regions is strongly influenced by fire, which converts biomass and detrital C mainly to gaseous forms (CO2 and smaller proportions of CO and CH4), and some 1-3% of mass to pyrogenic C (PyC). PyC is mainly produced as solid charred residues, including visually-defined charcoal, and a black carbon (BC) fraction chemically defined by its resistance to laboratory oxidation, plus much lower proportions of volatile soot and polycyclic aromatic hydrocarbons (PAHs). All PyC is characterized by fused aromatic rings, but varying in cluster sizes, and presence of other elements (N, O) and functional groups. The range of PyC structures is often described as a continuum from partially charred plant materials, to charcoal, soot and ultimately graphite which is formed by the combination of heat and pressure. There are several reasons for current interest in defining more precisely the role of PyC in the C cycle of boreal regions. First, PyC is largely resistant to decomposition, and therefore contributes to very stable C pools in soils and sediments. Second, it influences soil processes, mainly through its sorption properties and cation exchange capacity, and third, soot aerosols absorb solar radiation and may contribute to global warming. However, there are large gaps in the basic information needed to address these topics. While charcoal is commonly defined by visual criteria, analytical methods for BC are mainly based on various measures of oxidation resistance, or on yield of benzenepolycarboxylic acids. These methods are still being developed, and capture different fractions of the PyC structural continuum. There are few quantitative reports of PyC production and stocks in boreal forests (essentially none for boreal peatlands), and results are difficult to compare due to varying experimental goals and methods, as well as inconsistent terminology. There are almost no direct field measurements of BC aerosol production from boreal wildfires, and little direct information on rates and mechanisms for PyC loss. Structural characterization of charred biomass and forest floor from wildfires generally indicates a low level of thermal alteration, with the bulk of the material having H/C ratios still >0.2, and small aromatic cluster sizes. Especially for the more oxidation-resistant BC fraction, a variety of mainly circumstantial evidence suggests very slow decomposition, with turnover on a millennial timescale (in the order of 5-7 ky), also dependent on environmental conditions. However, there is also evidence that some PyC may be lost in only tens to hundreds of years due to a combination of lower thermal alteration and environmental protection. The potential for long-term PyC storage in soil may also be limited by its consumption by subsequent fires. Degraded, functionalized PyC is also incorporated into humified soil organic matter, and is transported eventually to marine sediments in dissolved and particulate form. Boreal production is estimated as 7-17 TgBCy-1 of solid residues and 2-2.5 TgBCy-1 as aerosols, compared to global estimates of 40-240 and 10-30TgBCy-1, respectively. Primary research needs include basic field data on PyC production and stocks in boreal forests and peatlands, suitable to support C budget modeling, and development of standardized analytical methods and of improved approaches to assess the chemical recalcitrance of typical chars from boreal wildfires. To accomplish these goals effectively will require much greater emphasis on interdisciplinary cooperation.},
author = {Preston, C. M. and Schmidt, M. W.I.},
doi = {10.5194/bg-3-397-2006},
file = {:home/brad/Dropbox/papers/Preston_Schmidt2006.pdf:pdf},
issn = {17264189},
journal = {Biogeosciences},
number = {4},
pages = {397--420},
title = {{Black (pyrogenic) carbon: A synthesis of current knowledge and uncertainties with special consideration of boreal regions}},
volume = {3},
year = {2006}
}
@article{Duthie2015b,
author = {Duthie, A Bradley and Abbott, Karen C and Nason, John D},
doi = {10.1086/681621},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duthie, Abbott, Nason - 2015 - Trade-offs and coexistence in fluctuating environments evidence for a key dispersal-fecundity trade-off i.pdf:pdf},
issn = {00030147},
journal = {American Naturalist},
keywords = {coexistence,competition,dispersal,ephemeral patch,fi g wasp,ficus,trade-offs},
number = {1},
pages = {151--158},
title = {{Trade-offs and coexistence in fluctuating environments: evidence for a key dispersal-fecundity trade-off in five nonpollinating fig wasps}},
url = {http://www.jstor.org/stable/info/10.1086/681621},
volume = {186},
year = {2015}
}
@article{Duthie2016,
abstract = {Community assembly rules have been extensively studied, but its association with regional environmental variation, while land use history remains largely unexplored. Land use history might be especially important in Mediterranean forests, considering their historical deforestation and recent afforestation. Using forest inventories and historical (1956) and recent (2000) land cover maps, we explored the following hypotheses: 1) woody species assembly is driven by environmental factors, but also by historical landscape attributes; 2) recent forests exhibit lower woody species richness than pre-existing due to the existence of colonization credits; 3) these credits are modulated by species' life-forms and dispersal mechanisms. We examined the association of forest historical type (pre-existing versus recent) with total species richness and that of diverse life-forms and dispersal groups, also considering the effects of current environment and past landscape factors. When accounting for these effects, no significant differences in woody species richness were found between forest historical types except for vertebrate-dispersed species. Species richness of this group was affected by the interaction of forest historical type with distance to coast and rainfall: vertebrate-dispersed species richness increased with rainfall and distance to the coast in recent forests, while it was higher in dryer sites in pre-existing forests. In addition, forest historical types showed differences in woody species composition associated to diverse environmental and past landscape factors. In view of these results we can conclude that: 1) community assembly in terms of species richness is fast enough to exhaust most colonization credit in recent Mediterranean forests except for vertebrate-dispersed species; 2) for these species, colonization credit is affected by the interplay of forest history and a set of proxies of niche and landscape constraints of species dispersal and establishment; 3) woody species assemblage is mostly shaped by the species' ecological niches in these forests.},
author = {Duthie, A Bradley and Nason, John D},
doi = {10.1111/oik.02629},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duthie, Nason - 2016 - Plant connectivity underlies plant-pollinator-exploiter distributions in Ficus petiolaris and associated pollinat.pdf:pdf},
isbn = {6503251521},
journal = {Oikos},
title = {{Plant connectivity underlies plant-pollinator-exploiter distributions in Ficus petiolaris and associated pollinating and non-pollinating fig wasps}},
year = {2016}
}
@article{Quinn1995,
abstract = {An outline is given of the organizational structure of the Convention du M{\`{e}}tre, the basis for international agreement on units of measurement, followed by a brief discussion on why accurate measurements are required. The Syst{\`{e}}me International d'Unit{\'{e}}s (SI) is introduced and the definition and practical realization of each of its base units are discussed. Prospects for improvements in their practical realizations and, in the case of the kilogram, prospects for a new definition based on atomic or fundamental constants are outlined.},
author = {Quinn, T. J.},
doi = {10.1088/0026-1394/31/6/011},
file = {:home/brad/Dropbox/papers/Quinn1994.pdf:pdf},
issn = {00261394},
journal = {Metrologia},
number = {6},
pages = {515--527},
title = {{Base units of the Syst{\`{e}}me International d'Unit{\'{e}}s, their accuracy, dissemination and international traceability}},
volume = {31},
year = {1995}
}
@article{Stock2019,
abstract = {An error has been found in the first paragraph of section 8, where it is stated that the definition of the second is based on a microwave transition frequency of the caesium 137 atom. The correct phrase is: Aside from restructuring the definition of the second to be consistent with the definitions of the other base units approved by the CGPM in 2018, there has been no change to the definition adopted in 1967, which is based on a microwave transition frequency of the caesium 133 atom.},
author = {Stock, Michael and Davis, Richard and {De Mirand{\'{e}}s}, Estefan{\'{i}}a and Milton, Martin J.T.},
doi = {10.1088/1681-7575/ab28a8},
file = {:home/brad/Dropbox/papers/StockEtAl2019.pdf:pdf},
issn = {16817575},
journal = {Metrologia},
number = {4},
title = {{Corrigendum: The revision of the SI - The result of three decades of progress in metrology (Metrologia (2019) 56 (022001) DOI: 10.1088/1681-7575/ab0013)}},
volume = {56},
year = {2019}
}
@book{Rabinovich2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Rabinovich, Semyon G.},
booktitle = {Evaluating Measurement Accuracy},
doi = {10.1007/978-1-4614-6717-5},
file = {:home/brad/Dropbox/papers/Rabinovich2013.pdf:pdf},
isbn = {9781461467168},
title = {{Evaluating Measurement Accuracy}},
year = {2013}
}
@article{Kelleher2011,
abstract = {Our ability to visualize scientific data has evolved significantly over the last 40 years. However, this advancement does not necessarily alleviate many common pitfalls in visualization for scientific journals, which can inhibit the ability of readers to effectively understand the information presented. To address this issue within the context of visualizing environmental data, we list ten guidelines for effective data visualization in scientific publications. These guidelines support the primary objective of data visualization, i.e. to effectively convey information. We believe that this small set of guidelines based on a review of key visualization literature can help researchers improve the communication of their results using effective visualization. Enhancement of environmental data visualization will further improve research presentation and communication within and across disciplines. {\textcopyright} 2011 Elsevier Ltd.},
author = {Kelleher, Christa and Wagener, Thorsten},
doi = {10.1016/j.envsoft.2010.12.006},
file = {:home/brad/Dropbox/papers/Kelleher_Wagener2011.pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling and Software},
keywords = {Data visualization,Scientific visualization,Visual analytics},
number = {6},
pages = {822--827},
publisher = {Elsevier Ltd},
title = {{Ten guidelines for effective data visualization in scientific publications}},
url = {http://dx.doi.org/10.1016/j.envsoft.2010.12.006},
volume = {26},
year = {2011}
}
@article{Elavsky2022,
abstract = {Novices and experts have struggled to evaluate the accessibility of data visualizations because there are no common shared guidelines across environments, platforms, and contexts in which data visualizations are authored. Between non-specific standards bodies like WCAG, emerging research, and guidelines from specific communities of practice, it is hard to organize knowledge on how to evaluate accessible data visualizations. We present Chartability, a set of heuristics synthesized from these various sources which enables designers, developers, researchers, and auditors to evaluate data-driven visualizations and interfaces for visual, motor, vestibular, neurological, and cognitive accessibility. In this paper, we outline our process of making a set of heuristics and accessibility principles for Chartability and highlight key features in the auditing process. Working with participants on real projects, we found that data practitioners with a novice level of accessibility skills were more confident and found auditing to be easier after using Chartability. Expert accessibility practitioners were eager to integrate Chartability into their own work. Reflecting on Chartability's development and the preliminary user evaluation, we discuss tradeoffs of open projects, working with high-risk evaluations like auditing projects in the wild, and challenge future research projects at the intersection of visualization and accessibility to consider the broad intersections of disabilities.},
author = {Elavsky, Frank and Bennett, Cynthia and Moritz, Dominik},
doi = {10.1111/cgf.14522},
file = {:home/brad/Dropbox/papers/ElavskyEtAl2022.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Accessibility design and evaluation methods,CCS Concepts,Heuristic evaluations,• Human-centered computing → Visualization design and evaluation methods},
number = {3},
pages = {57--70},
title = {{How accessible is my visualization? Evaluating visualization accessibility with Chartability}},
volume = {41},
year = {2022}
}
@book{Miller2004,
address = {Upper Saddle River, New Jersey},
author = {Miller, Irwin and Miller, Marylees},
edition = {7},
pages = {614},
publisher = {Pearson Prentice Hall},
title = {{John E. Freund's mathematical statistics}},
year = {2004}
}
@article{Law2014,
abstract = {With the global population of beavers (Castor spp.) increasing, and reintroductions widespread, it is crucial to be able to predict potential impacts on flora and fauna based on defined foraging behaviours. Nymphaea alba (white water lily) is regularly consumed by beavers and provides a model system to test selective foraging behaviour and quantify potential impacts on aquatic resources in standing-water habitats. Using biometric relationships within N. alba pads, we accurately reconstructed the size and weight of consumed pads, demonstrating that beavers (Castor fiber) selected pads that were significantly larger and heavier than unselected pads. By selecting larger leaves, beavers may also avoid chemical defences associated with anthocyanin pigments that dominate in smaller leaves. Grazing was concentrated in shallow depths (55.7 ± 10.7 cm) close to the shore (2.95 ± 0.62 m) relative to ungrazed plots (100.5 ± 9.2 cm; 4.79 ± 0.68 m). The level of selectivity was unchanged with increasing distance from a central feeding place. Beavers removed 24-50% of pads within grazed areas, but relative to the whole N. alba leaf pad resource, the impact of this foraging was low (0.38-1.23% loss). Plant species diversity was unaffected by foraging, and there was no evidence of indirect effects on non-targeted N. alba pads or flowers. When foraging in the aquatic environment, beavers are highly selective and can have a minor effect on food resources whilst feeding optimally and opportunistically. Since beavers demonstrate adaptive foraging strategies depending on their foraging environment, this knowledge should be incorporated into future decisions on further reintroduction or habitat restoration programmes. {\textcopyright} 2013 John Wiley & Sons Ltd.},
author = {Law, A. and Bunnefeld, N. and Willby, N. J.},
doi = {10.1111/fwb.12259},
file = {:home/brad/Dropbox/papers/LawEtAl2014.pdf:pdf},
issn = {00465070},
journal = {Freshwater Biology},
keywords = {Aquatic plants,Castor fiber,Foraging,Nymphaea alba,Selectivity},
number = {2},
pages = {224--232},
title = {{Beavers and lilies: Selective herbivory and adaptive foraging behaviour}},
volume = {59},
year = {2014}
}
@article{Hyndman1996,
abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution. {\textcopyright} 1996 Taylor & Francis Group, LLC.},
author = {Hyndman, Rob J. and Fan, Yanan},
doi = {10.1080/00031305.1996.10473566},
file = {:home/brad/Dropbox/papers/Hyndman_Fan1996.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
keywords = {Percentiles,Quartiles,Sample quantiles,Statistical computer packages},
number = {4},
pages = {361--365},
title = {{Sample Quantiles in Statistical Packages}},
volume = {50},
year = {1996}
}
@article{Rihs2018,
  title={distrACTION-Calculating and Plotting Distributions},
  author={Rihs, Michael and Mayer, Boris},
  year={2018},
  publisher={jamovi. org}
}
@article{Pelabon2020,
abstract = {Meaningful comparison of variation in quantitative trait requires controlling for both the dimension of the varying entity and the dimension of the factor generating variation. Although the coefficient of variation (CV; standard deviation divided by the mean) is often used to measure and compare variation of quantitative traits, it only accounts for the dimension of the former, and its use for comparing variation may sometimes be inappropriate. Here, we discuss the use of the CV to compare measures of evolvability and phenotypic plasticity, two variational properties of quantitative traits. Using a dimensional analysis, we show that contrary to evolvability, phenotypic plasticity cannot be meaningfully compared across traits and environments by mean-scaling trait variation. We further emphasize the need of remaining cognizant of the dimensions of the traits and the relationship between mean and standard deviation when comparing CVs, even when the scales on which traits are expressed allow meaningful calculation of the CV.},
author = {P{\'{e}}labon, Christophe and Hilde, Christoffer H and Einum, Sigurd and Gamelon, Marl{\`{e}}ne},
doi = {10.1002/evl3.171},
file = {:home/brad/Dropbox/papers/PelabonEtAl2020.pdf:pdf},
issn = {20563744},
journal = {Evolution Letters},
keywords = {Dimensional analyses,genetic variance,measurement theory,quantitative genetics,teaching},
number = {3},
pages = {180--188},
title = {{On the use of the coefficient of variation to quantify and compare trait variation}},
volume = {4},
year = {2020}
}
@article{Lande1977,
author = {Lande, Russell},
file = {:home/brad/Dropbox/papers/Lande1977.pdf:pdf},
journal = {Systematic Zoology},
number = {2},
pages = {214--217},
title = {{On comparing coefficients of variation.}},
volume = {26},
year = {1977}
}
@article{Wickham2014,
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
author = {Wickham, Hadley},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickham - 2014 - Tiday Data.pdf:pdf},
journal = {Journal of Statistical Software},
keywords = {data cleaning,data tidying,r,relational databases},
number = {10},
pages = {1--23},
title = {{Tiday Data}},
url = {http://www.jstatsoft.org/},
volume = {59},
year = {2014}
}
@book{Rencher2000,
address = {Provo, Utah},
author = {Rencher, Alivn C},
pages = {578},
publisher = {John Wiley \& Sons, Inc},
title = {{Linear Models in Statistics}},
year = {2000}
}
@article{Mclean1991,
author = {Mclean, Robert A and Sanders, William L and Stroup, Walter W},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mclean, Sanders, Stroup - 1991 - A unified approach to mixed linear models.pdf:pdf},
journal = {American Statistician},
keywords = {best linear unbiased prediction,correct,even though other authors,expectations,have presented a different,hocking 1985,inference,kirk 1982,mood 1950,searle 1971,set of,these are the},
number = {1},
pages = {54--64},
title = {{A unified approach to mixed linear models}},
volume = {45},
year = {1991}
}
@book{Courant1996,
address = {Oxford},
author = {Courant, Richard and Robbins, Herbert and Stewart, Ian},
edition = {2},
pages = {566},
publisher = {Oxford University Press},
title = {{What is Mathematics?}},
year = {1996}
}
@book{Pastor2008,
address = {West Sussex, England},
author = {Pastor, John},
pages = {1--50},
publisher = {John Wiley \& Sons, Inc},
title = {{Mathematical Ecoogy of Populations and Ecosystems}},
year = {2008}
}
@article{Askey1999,
abstract = {... Con- trast the inadequate treatment of the multiplication of negative numbers described above to the way Gelfand and Shen handle the topic.2 Although their presenta- tion would need to be fleshed out more if it's being pre- sented to students for the first time, it provides us with ...},
author = {Askey, R},
file = {:home/brad/Dropbox/papers/Askey1999.pdf:pdf},
journal = {American Educator},
pages = {4--5},
title = {{Why does a negative x a negative = a positive?}},
url = {http://homepages.math.uic.edu/~saunders/MTHT467_2011/AskeyGelfand.pdf},
year = {1999}
}
@techreport{Yee2019,
author = {Yee, Alexander J},
title = {{Google Cloud Topples the Pi Record}},
url = {http://www.numberworld.org/blogs/2019_3_14_pi_record/},
year = {2019}
}
@book{Stewart2008,
address = {London},
author = {Stewart, Ian},
pages = {384},
publisher = {Quercus},
title = {{Taming the Infinite}},
year = {2008}
}
@article{Friedlingstein2022,
author = {Friedlingstein, P. and O'Sullivan, M. and Jones, M. W. and Andrew, R. M. and Gregor, L. and Hauck, J. and Le Qu\'er\'e, C. and Luijkx, I. T. and Olsen, A. and Peters, G. P. and Peters, W. and Pongratz, J. and Schwingshackl, C. and Sitch, S. and Canadell, J. G. and Ciais, P. and Jackson, R. B. and Alin, S. R. and Alkama, R. and Arneth, A. and Arora, V. K. and Bates, N. R. and Becker, M. and Bellouin, N. and Bittig, H. C. and Bopp, L. and Chevallier, F. and Chini, L. P. and Cronin, M. and Evans, W. and Falk, S. and Feely, R. A. and Gasser, T. and Gehlen, M. and Gkritzalis, T. and Gloege, L. and Grassi, G. and Gruber, N. and G\"urses, \"O. and Harris, I. and Hefner, M. and Houghton, R. A. and Hurtt, G. C. and Iida, Y. and Ilyina, T. and Jain, A. K. and Jersild, A. and Kadono, K. and Kato, E. and Kennedy, D. and Klein Goldewijk, K. and Knauer, J. and Korsbakken, J. I. and Landsch\"utzer, P. and Lef\`evre, N. and Lindsay, K. and Liu, J. and Liu, Z. and Marland, G. and Mayot, N. and McGrath, M. J. and Metzl, N. and Monacci, N. M. and Munro, D. R. and Nakaoka, S.-I. and Niwa, Y. and O'Brien, K. and Ono, T. and Palmer, P. I. and Pan, N. and Pierrot, D. and Pocock, K. and Poulter, B. and Resplandy, L. and Robertson, E. and R\"odenbeck, C. and Rodriguez, C. and Rosan, T. M. and Schwinger, J. and S\'ef\'erian, R. and Shutler, J. D. and Skjelvan, I. and Steinhoff, T. and Sun, Q. and Sutton, A. J. and Sweeney, C. and Takao, S. and Tanhua, T. and Tans, P. P. and Tian, X. and Tian, H. and Tilbrook, B. and Tsujino, H. and Tubiello, F. and van der Werf, G. R. and Walker, A. P. and Wanninkhof, R. and Whitehead, C. and Willstrand Wranne, A. and Wright, R. and Yuan, W. and Yue, C. and Yue, X. and Zaehle, S. and Zeng, J. and Zheng, B.},
title = {Global Carbon Budget 2022},
journal = {Earth System Science Data},
volume = {14},
year = {2022},
number = {11},
pages = {4811--4900},
url = {https://essd.copernicus.org/articles/14/4811/2022/},
doi = {10.5194/essd-14-4811-2022}
}
@book{Gotelli2001,
address = {Sunderland, Massachusetts},
author = {Gotelli, Nicholas J},
edition = {3},
pages = {265},
publisher = {Sinauer Associates, Inc.},
title = {{Gotelli}},
year = {2001}
}
@misc{Chernoff2022,
author = {Chernoff, Egan J and Zazkis, Rina},
booktitle = {The Conversation},
title = {{The simple reason a viral math equation stumped the internet}},
url = {https://theconversation.com/the-simple-reason-a-viral-math-equation-stumped-the-internet-176518},
urldate = {27 DEC 2022},
year = {2022}
}
@article{Weiblen2002,
author = {Weiblen, George D},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiblen - 2002 - How to be a fig wasp.pdf:pdf},
journal = {Annual Review of Entomology},
keywords = {200 papers have appeared,a fig,agaonidae,and their host plants,coevolution,cospeciation,described how to be,ficus spp,fig pollination is now,model system for the,moraceae,more than,on fig wasps,parasitism,pollination,s abstract in the,study of,two decades since janzen,widely regarded as a},
pages = {299--330},
title = {{How to be a fig wasp}},
volume = {47},
year = {2002}
}
@article{Mayo2021,
abstract = {The crisis of replication has led many to blame statistical significance tests for making it too easy to find impressive looking effects that do not replicate. However, the very fact it becomes difficult to replicate effects when features of the tests are tied down actually serves to vindicate statistical significance tests. While statistical significance tests, used correctly, serve to bound the probabilities of erroneous interpretations of data, this error control is nullified by data-dredging, multiple testing, and other biasing selection effects. Arguments claiming to vitiate statistical significance tests attack straw person variants of tests that commit well-known fallacies and misinterpretations. There is a tension between popular calls for preregistration – arguably, one of the most promising ways to boost replication – and accounts that downplay error probabilities: Bayes Factors, Bayesian posteriors, likelihood ratios. By underscoring the importance of error control for well testedness, the replication crisis points to reformulating tests so as to avoid fallacies and report the extent of discrepancies that are and are not indicated with severity.},
author = {Mayo, Deborah G.},
doi = {10.1007/s13164-020-00501-w},
file = {:home/brad/Dropbox/papers/Mayo2021.pdf:pdf},
issn = {18785166},
journal = {Review of Philosophy and Psychology},
keywords = {Crisis of replication,Data dredging,Preregistration,Severe testing,Statistical significance},
number = {1},
pages = {101--120},
publisher = {Review of Philosophy and Psychology},
title = {{Significance Tests: Vitiated or Vindicated by the Replication Crisis in Psychology?}},
volume = {12},
year = {2021}
}
@book{Edwards1972,
address = {Cambridge},
author = {Edwards, A W F},
pages = {235},
publisher = {Cambridge University Press},
title = {{Likelihood: An account of the statistical concept of likelihood and its application to scientific inference}},
year = {1972}
}
@book{Mayo1996,
address = {Chicago},
author = {Mayo, Deborah G},
pages = {493},
publisher = {University of Chicago Press},
title = {{Error and the Growth of Experimental Knowledge}},
year = {1996}
}
@article{Gelman2013,
abstract = {A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico-deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science. Clarity about these matters should benefit not just philosophy of science, but also statistical practice. At best, the inductivist view has encouraged researchers to fit and compare models without checking them; at worst, theorists have actively discouraged practitioners from performing model checking because it does not fit into their framework. {\textcopyright} 2012 The British Psychological Society.},
archivePrefix = {arXiv},
arxivId = {1006.3868},
author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
doi = {10.1111/j.2044-8317.2011.02037.x},
eprint = {1006.3868},
file = {:home/brad/Dropbox/papers/Gelman_Shalizi2013.pdf:pdf},
issn = {00071102},
journal = {British Journal of Mathematical and Statistical Psychology},
number = {1},
pages = {8--38},
pmid = {22364575},
title = {{Philosophy and the practice of Bayesian statistics}},
volume = {66},
year = {2013}
}
@book{Suarez2020,
address = {Cambridge},
author = {Su\'{a}rez, Mauricio},
doi = {10.1017/9781108985826},
editor = {Northcott, Robert and Stegenga, Jacob},
pages = {72},
publisher = {Cambridge University Press},
title = {{Philosophy of Probability and Statistical Modelling}},
year = {2020}
}
@article{Hardy1908,
abstract = {Hardy illustrating that populations will not change under specific conditions.},
archivePrefix = {arXiv},
arxivId = {arXiv:astro-ph/0607208},
author = {Hardy, G H},
doi = {10.1126/science.28.706.49},
eprint = {0607208},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardy - 1908 - Mendelian proportions in a mixed population.pdf:pdf},
isbn = {0036-8075 (Print)\n0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science},
number = {706},
pages = {49--50},
pmid = {17779291},
primaryClass = {arXiv:astro-ph},
title = {{Mendelian proportions in a mixed population}},
volume = {28},
year = {1908}
}
@article{Adams2016,
abstract = {Evolutionary morphologists frequently wish to understand the extent to which organisms are integrated, and whether the strength of morphological integration among subsets of phenotypic variables differ among taxa or other groups. However, comparisons of the strength of integration across datasets are difficult, in part because the summary measures that characterize these patterns (RV coefficient and rPLS) are dependent both on sample size and on the number of variables. As a solution to this issue, we propose a standardized test statistic (a z-score) for measuring the degree of morphological integration between sets of variables. The approach is based on a partial least squares analysis of trait covariation, and its permutation-based sampling distribution. Under the null hypothesis of a random association of variables, the method displays a constant expected value and confidence intervals for datasets of differing sample sizes and variable number, thereby providing a consistent measure of integration suitable for comparisons across datasets. A two-sample test is also proposed to statistically determine whether levels of integration differ between datasets, and an empirical example examining cranial shape integration in Mediterranean wall lizards illustrates its use. Some extensions of the procedure are also discussed.},
author = {Adams, Dean C and Collyer, Michael L},
doi = {10.1111/evo.13045},
file = {:home/brad/Dropbox/papers/Adams_Collyer2016.pdf:pdf},
issn = {15585646},
journal = {Evolution},
keywords = {Geometric morphometrics,Morphological evolution,morphological integration},
number = {11},
pages = {2623--2631},
pmid = {27592864},
title = {{On the comparison of the strength of morphological integration across morphometric datasets}},
volume = {70},
year = {2016}
}
@article{Cheadle2003,
abstract = {High-throughput cDNA microarray technology allows for the simultaneous analysis of gene expression levels for thousands of genes and as such, rapid, relatively simple methods are needed to store, analyze, and cross-compare basic microarray data. The application of a classical method of data normalization, Z score transformation, provides a way of standardizing data across a wide range of experiments and allows the comparison of microarray data independent of the original hybridization intensities. Data normalized by Z score transformation can be used directly in the calculation of significant changes in gene expression between different samples and conditions. We used Z scores to compare several different methods for predicting significant changes in gene expression including fold changes, Z ratios, Z and t statistical tests. We conclude that the Z score transformation normalization method accompanied by either Z ratios or Z tests for significance estimates offers a useful method for the basic analysis of microarray data. The results provided by these methods can be as rigorous and are no more arbitrary than other test methods, and, in addition, they have the advantage that they can be easily adapted to standard spreadsheet programs.},
author = {Cheadle, Chris and Vawter, Marquis P and Freed, William J and Becker, Kevin G},
doi = {10.1016/S1525-1578(10)60455-2},
file = {:home/brad/Dropbox/papers/CheadleEtAl2003.pdf:pdf},
issn = {15251578},
journal = {Journal of Molecular Diagnostics},
number = {2},
pages = {73--81},
pmid = {12707371},
publisher = {American Society for Investigative Pathology and Association for Molecular Pathology},
title = {{Analysis of microarray data using Z score transformation}},
url = {http://dx.doi.org/10.1016/S1525-1578(10)60455-2},
volume = {5},
year = {2003}
}
@article{Ellison2004,
author = {Ellison, Aaron M},
doi = {10.1111/j.1461-0248.2004.00603.x},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ellison - 2004 - Bayesian inference in ecology.pdf:pdf},
issn = {1461-023X},
journal = {Ecology Letters},
keywords = {2004,509,520,7,averaging,bayesian inference,bayes{\~{o}} theorem,ecology letters,epistemology,information criteria,model,model selection},
month = {jun},
number = {6},
pages = {509--520},
title = {{Bayesian inference in ecology}},
url = {http://doi.wiley.com/10.1111/j.1461-0248.2004.00603.x},
volume = {7},
year = {2004}
}
@book{Borowski2005,
address = {London},
author = {Borowski, E J and Borwein, J M},
edition = {2},
pages = {641},
publisher = {HarperCollins Publishers},
title = {{Collins Dictionary of Mathematics}},
year = {2005}
}
@article{Fedor-Freybergh2006,
author = {Fedor-Freybergh, Peter G and Mikuleck{\'{y}}, Miroslav},
file = {:home/brad/Dropbox/papers/Fedor-Freybergh_Mikulecky2005.pdf:pdf},
issn = {0172780X},
journal = {Neuroendocrinology Letters},
number = {3},
pages = {292},
title = {{Erratum: From the descriptive towards inferential statistics: Hundred years since conception of the Student's t-distribution}},
volume = {27},
year = {2006}
}
@article{Fuentes-Montemayor2022,
author = {Fuentes-Montemayor, Elisa and Park, Kirsty J and Cordts, Kypfer and Watts, Kevin},
doi = {10.1093/forestry/cpab027},
file = {:home/brad/Dropbox/papers/Fuentes-Montemayor2022.pdf:pdf},
journal = {Forestry},
number = {June 2021},
pages = {28--37},
title = {{The long-term development of temperate woodland creation sites: from tree saplings to mature woodlands}},
url = {https://doi.org/10.1093/forestry/cpab027},
volume = {95},
year = {2022}
}
@article{Fuentes-Montemayor2022a,
abstract = {Aim: Large-scale habitat creation is crucial to mitigate the current ecological crisis, but scientific evidence on its effects on biodiversity is scarce. Here, we assess how assemblages of a biodiverse group (moths) develop over time in habitat creation sites. We use temperate woodlands as a case study, and compare species assemblages in restored and mature habitat patches. We also identify local- and landscape-level attributes associated with high species richness and abundance. Location: Central Scotland, United Kingdom. Methods: We surveyed moths in a chronosequence of 79 temperate woodland patches encompassing woodland creation sites (20–160 years old) and mature “ancient” woodlands (250+ years old). We used structural equation models, generalized linear models and ordination techniques to quantify moth community responses to woodland creation, and degree of similarity to moth assemblages in ancient woodlands. Results: Woodland creation sites harboured large numbers of moth species (212), were dominated by woodland generalists and had high species turnover. Moth abundance and diversity increased with woodland connectivity. Macromoths were more abundant and diverse in younger woodlands; micromoth specialists occurred more frequently in older woodland creation sites. Ancient woodlands had similar moth abundance/richness than woodland creation sites (except for fewer macromoth woodland specialist species), but their species composition was somewhat different. Patterns of beta diversity (low nestedness) indicated that moth species in woodland creation sites are not simply subsets of species in ancient woodlands. Main conclusions: To benefit moth communities, woodland creation sites should be structurally diverse and in close proximity to other woodlands. At the landscape scale, a mosaic of woodland patches of different ages is likely to increase moth beta (and consequently gamma) diversity. Ancient woodlands and woodland creation sites each host substantial proportions of “unique” species; individual woodland patches contain distinctive moth assemblages and should be protected and valued for their contribution to regional moth diversity.},
author = {Fuentes-Montemayor, Elisa and Watts, Kevin and Sansum, Philip and Scott, Will and Park, Kirsty J},
doi = {10.1111/ddi.13599},
file = {:home/brad/Dropbox/papers/Fuentes-Montemayor2021.pdf:pdf},
issn = {14724642},
journal = {Diversity and Distributions},
keywords = {Lepidoptera,WrEN project,afforestation,moths,reforestation,restoration,tree planting,woodland creation,woodland expansion},
number = {9},
pages = {1993--2007},
title = {{Moth community responses to woodland creation: The influence of woodland age, patch characteristics and landscape attributes}},
url = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ddi.13599},
volume = {28},
year = {2022}
}
@book{Bouma2000,
address = {Oxford, UK},
author = {Bouma, Gary D},
edition = {4},
pages = {242},
publisher = {Oxford University Press},
title = {{The Research Process}},
year = {2000}
}
@article{Greenland2016,
abstract = {Misinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so—and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.},
author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
doi = {10.1007/s10654-016-0149-3},
file = {:home/brad/Dropbox/papers/GreenlandEtAl2016.pdf:pdf},
issn = {15737284},
journal = {European Journal of Epidemiology},
keywords = {Confidence intervals,Hypothesis testing,Null testing,P value,Power,Significance tests,Statistical testing},
number = {4},
pages = {337--350},
pmid = {27209009},
publisher = {Springer Netherlands},
title = {{Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations}},
volume = {31},
year = {2016}
}
@article{Wasserstein2016,
author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
doi = {10.1080/00031305.2016.1154108},
file = {:home/brad/Dropbox/papers/Wasserstein_Lazar2016.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
number = {2},
pages = {129--133},
publisher = {Taylor & Francis},
title = {{The ASA's Statement on p-Values: Context, Process, and Purpose}},
url = {http://dx.doi.org/10.1080/00031305.2016.1154108},
volume = {70},
year = {2016}
}
@article{Stanton-Geddes2014,
author = {Stanton-Geddes, John and {De Freitas}, Cintia Gomes and {De Sales Dambros}, Cristian},
doi = {10.1890/13-1156.1},
file = {:home/brad/Dropbox/papers/Stanton-GeddesEtAl2014.pdf:pdf},
issn = {00129658},
journal = {Ecology},
number = {3},
pages = {637--642},
pmid = {24804446},
title = {{In defense of P values: Comment on the statistical methods actually used by ecologists}},
volume = {95},
year = {2014}
}
@article{Mayo2019,
author = {Mayo, Deborah G.},
doi = {10.1111/eci.13170},
file = {:home/brad/Dropbox/papers/Mayo2019.pdf:pdf},
issn = {13652362},
journal = {European Journal of Clinical Investigation},
number = {10},
pages = {1--4},
title = {{P-value thresholds: Forfeit at your peril}},
volume = {49},
year = {2019}
}
@article{McShane2019,
abstract = {We discuss problems the null hypothesis significance testing (NHST) paradigm poses for replication and more broadly in the biomedical and social sciences as well as how these problems remain unresolved by proposals involving modified p-value thresholds, confidence intervals, and Bayes factors. We then discuss our own proposal, which is to abandon statistical significance. We recommend dropping the NHST paradigm—and the p-value thresholds intrinsic to it—as the default statistical paradigm for research, publication, and discovery in the biomedical and social sciences. Specifically, we propose that the p-value be demoted from its threshold screening role and instead, treated continuously, be considered along with currently subordinate factors (e.g., related prior evidence, plausibility of mechanism, study design and data quality, real world costs and benefits, novelty of finding, and other factors that vary by research domain) as just one among many pieces of evidence. We have no desire to “ban” p-values or other purely statistical measures. Rather, we believe that such measures should not be thresholded and that, thresholded or not, they should not take priority over the currently subordinate factors. We also argue that it seldom makes sense to calibrate evidence as a function of p-values or other purely statistical measures. We offer recommendations for how our proposal can be implemented in the scientific publication process as well as in statistical decision making more broadly.},
archivePrefix = {arXiv},
arxivId = {1709.07588},
author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.},
doi = {10.1080/00031305.2018.1527253},
eprint = {1709.07588},
file = {:home/brad/Dropbox/papers/McShaneEtAl2019.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
keywords = {Null hypothesis significance testing,Replication,Sociology of science,Statistical significance,p-Value},
pages = {235--245},
title = {{Abandon Statistical Significance}},
volume = {73},
year = {2019}
}
@article{Ruxton2006,
author = {Ruxton, Graeme D.},
doi = {10.1093/beheco/ark016},
file = {:home/brad/Dropbox/papers/Ruxton2006.pdf:pdf},
issn = {10452249},
journal = {Behavioral Ecology},
number = {4},
pages = {688--690},
title = {{The unequal variance t-test is an underused alternative to Student's t-test and the Mann-Whitney U test}},
volume = {17},
year = {2006}
}
@article{Welch1938,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. Biometrika Trust is collaborating with JSTOR to digitize, preserve and extend access to Biometrika.},
author = {Welch, B. L.},
doi = {10.2307/2332010},
file = {:home/brad/Dropbox/papers/Welch1938.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
number = {3/4},
pages = {350},
title = {{The Significance of the Difference Between Two Means when the Population Variances are Unequal}},
volume = {29},
year = {1938}
}
@article{Delacre2017,
abstract = {When comparing two independent groups, psychology researchers commonly use Student's t-Tests. Assumptions of normality and homogeneity of variance underlie this test. More often than not, when these conditions are not met, Student's t-Test can be severely biased and lead to invalid statistical inferences. Moreover, we argue that the assumption of equal variances will seldom hold in psychological research, and choosing between Student's t-Test and Welch's t-Test based on the outcomes of a test of the equality of variances often fails to provide an appropriate answer. We show that the Welch's t-Test provides a better control of Type 1 error rates when the assumption of homogeneity of variance is not met, and it loses little robustness compared to Student's t-Test when the assumptions are met. We argue that Welch's t-Test should be used as a default strategy.},
author = {Delacre, Marie and Lakens, Dani{\"{e}}l and Leys, Christophe},
doi = {10.5334/irsp.82},
file = {:home/brad/Dropbox/papers/DelacreEtAl2017.pdf:pdf},
issn = {23978570},
journal = {International Review of Social Psychology},
keywords = {Homogeneity of variance,Homoscedasticity,Levene's test,Statistical power,Student's t-Test,Type 1 error,Type 2 error,Welch's t-Test},
number = {1},
pages = {92--101},
title = {{Why psychologists should by default use welch's t-Test instead of student's t-Test}},
volume = {30},
year = {2017}
}
@article{Johnson1995,
author = {Johnson, Douglas H},
file = {:home/brad/Dropbox/papers/Johnson1995.pdf:pdf},
journal = {Ecology},
keywords = {how often have you,hypothesis testing,nonparametric methods,normal distribution,our data,parameter estima-,read something like,so we used nonpara-,t test,tion,were not normally distributed,wilcoxon-mann-whitney test vs},
number = {6},
pages = {1998--2000},
title = {{Statistical sirens: The allure of nonparametrics}},
volume = {76},
year = {1995}
}
@article{Lumley2002,
author = {Lumley, Thomas and Diehr, Paula and Emerson, Scott and Chen, Lu},
doi = {10.1146/annurev.publheath.23.100901.140546},
file = {:home/brad/Dropbox/papers/LumleyEtAl2002.pdf:pdf},
journal = {Annual Review of Public Health},
keywords = {an outcome variable for,are valid only for,compare the mean of,different subjects,heteroscedasticity,linear regression,nonparametric,normally distributed outcomes,parametric,rank test,regression,s abstract it is,that the t-test and,the t-test and linear,while these are valid,widely but incorrectly believed,wilcoxon test},
pages = {151--169},
title = {{The importance of the normality assumption in large public health data sets}},
volume = {23},
year = {2002}
}
@article{Narum2006,
abstract = {Studies in conservation genetics often attempt to determine genetic differentiation between two or more temporally or geographically distinct sample collections. Pairwise p-values from Fisher's exact tests or contingency Chi-square tests are commonly reported with a Bonferroni correction for multiple tests. While the Bonferroni correction controls the experiment-wise $\alpha$, this correction is very conservative and results in greatly diminished power to detect differentiation among pairs of sample collections. An alternative is to control the false discovery rate (FDR) that provides increased power, but this method only maintains experiment-wise $\alpha$ when none of the pairwise comparisons are significant. Recent modifications to the FDR method provide a moderate approach to determining significance level. Simulations reveal that critical values of multiple comparison tests with both the Bonferroni method and a modified FDR method approach a minimum asymptote very near zero as the number of tests gets large, but the Bonferroni method approaches zero much more rapidly than the modified FDR method. I compared pairwise significance from three published studies using three critical values corresponding to Bonferroni, FDR, and modified FDR methods. Results suggest that the modified FDR method may provide the most biologically important critical value for evaluating significance of population differentiation in conservation genetics. Ultimately, more thorough reporting of statistical significance is needed to allow interpretation of biological significance of genetic differentiation among populations. {\textcopyright} 2006 Springer Science+Business Media, Inc.},
author = {Narum, Shawn R.},
doi = {10.1007/s10592-005-9056-y},
file = {:home/brad/Dropbox/papers/Narum2006.pdf:pdf},
issn = {15729737},
journal = {Conservation Genetics},
keywords = {Bonferroni,Conservation genetics,False discovery rate,Multiple comparison tests},
number = {5},
pages = {783--787},
title = {{Beyond Bonferroni: Less conservative analyses for conservation genetics}},
volume = {7},
year = {2006}
}
@article{Tukey1949,
author = {Tukey, John W},
file = {:home/brad/Dropbox/papers/Tukey1949.pdf:pdf},
journal = {Biometrics},
number = {2},
pages = {99--114},
title = {{Comparing individual means in the analysis of variance}},
volume = {5},
year = {1949}
}
@article{Blanca2018,
abstract = {Inconsistencies in the research findings on F-test robustness to variance heterogeneity could be related to the lack of a standard criterion to assess robustness or to the different measures used to quantify heterogeneity. In the present paper we use Monte Carlo simulation to systematically examine the Type I error rate of F-test under heterogeneity. One-way, balanced, and unbalanced designs with monotonic patterns of variance were considered. Variance ratio (VR) was used as a measure of heterogeneity (1.5, 1.6, 1.7, 1.8, 2, 3, 5, and 9), the coefficient of sample size variation as a measure of inequality between group sizes (0.16, 0.33, and 0.50), and the correlation between variance and group size as an indicator of the pairing between them (1,.50, 0, −.50, and −1). Overall, the results suggest that in terms of Type I error a VR above 1.5 may be established as a rule of thumb for considering a potential threat to F-test robustness under heterogeneity with unequal sample sizes.},
author = {Blanca, Mar{\'{i}}a J. and Alarc{\'{o}}n, Rafael and Arnau, Jaume and Bono, Roser and Bendayan, Rebecca},
doi = {10.3758/s13428-017-0918-2},
file = {:home/brad/Dropbox/papers/BlancaEtAl2018.pdf:pdf},
isbn = {1342801709},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {ANOVA,F-test,Heterogeneity,Robustness,Variance ratio},
number = {3},
pages = {937--962},
pmid = {28643157},
publisher = {Behavior Research Methods},
title = {{Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit?}},
volume = {50},
year = {2018}
}
@article{Schmider2010,
abstract = {Empirical evidence to the robustness of the analysis of variance (ANOVA) concerning violation of the normality assumption is presented by means of Monte Carlo methods. High-quality samples underlying normally, rectangularly, and exponentially distributed basic populations are created by drawing samples which consist of random numbers from respective generators, checking their goodness of fit, and allowing only the best 10% to take part in the investigation. A one-way fixed-effect design with three groups of 25 values each is chosen. Effectsizes are implemented in the samples and varied over a broad range. Comparing the outcomes of the ANOVA calculations for the different types of distributions, gives reason to regard the ANOVA as robust. Both, the empirical type I error a and the empirical type II error b remain constant under violation. Moreover, regression analysis identifies the factor "type of distribution" as not significant in explanation of the ANOVA results. {\textcopyright} 2010 Hogrefe Publishing.},
author = {Schmider, Emanuel and Ziegler, Matthias and Danay, Erik and Beyer, Luzi and B{\"{u}}hner, Markus},
doi = {10.1027/1614-2241/a000016},
file = {:home/brad/Dropbox/papers/SchmiderEtAl2010.pdf:pdf},
issn = {16141881},
journal = {Methodology},
keywords = {ANOVA,Assumption violation,High-quality samples,Monte Carlo,Normal distribution},
number = {4},
pages = {147--151},
title = {{Is It Really Robust?: Reinvestigating the robustness of ANOVA against violations of the normal distribution assumption}},
volume = {6},
year = {2010}
}
@article{Kruskal1952,
abstract = {Given C samples, with ni observations in the ith sample, a test of the hypothesis that the samples are from the same population may be made by ranking the observations from from 1 to $\Sigma$n i (giving each observation in a group of ties the mean of the ranks tied for), finding the C sums of ranks, and computing a statistic H. Under the stated hypothesis, H is distributed approximately as $\chi$2(C – 1), unless the samples are too small, in which case special approximations or exact tables are provided. One of the most important applications of the test is in detecting differences among the population means. Based in part on research supported by the Office of Naval Research at the Statistical Research Center, University of Chicago. Copyright Taylor & Francis Group, LLC.},
author = {Kruskal, William H and Wallis, W Allen},
doi = {10.1080/01621459.1952.10483441},
file = {:home/brad/Dropbox/papers/Kruskall_Wallis1952.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {260},
pages = {583--621},
title = {{Use of Ranks in One-Criterion Variance Analysis}},
volume = {47},
year = {1952}
}
@article{Kruskal1952a,
author = {Kruskal, William H.},
file = {:home/brad/Dropbox/papers/Kruskall1952.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {4},
pages = {525--540},
title = {{A nonparametric test for the several sample problem}},
volume = {23},
year = {1952}
}
@article{Choi2003,
abstract = {The Kruskal-Wallis test is a popular nonparametric test for comparing k independent samples. In this article we propose a new algorithm to compute the exact null distribution of the Kruskal-Wallis test. Generating the exact null distribution of the Kruskal-Wallis test is needed to compare several approximation methods. The 5% cut-off points of the exact null distribution which StatXact cannot produce are obtained as by-products. We also investigate graphically a reason that the exact and approximate distributions differ, and hope that it will be a useful tutorial tool to teach about the Kruskal-Wallis test in undergraduate course.},
author = {Choi, Won and Lee, Jae Won and Huh, Myung Hoe and Kang, Seung Ho},
doi = {10.1081/SAC-120023876},
file = {:home/brad/Dropbox/papers/ChoiEtAl2003.pdf:pdf},
isbn = {8223277360},
issn = {03610918},
journal = {Communications in Statistics Part B: Simulation and Computation},
keywords = {Nonparametric ANOVA,Permutation,Rank,Recursive formula},
number = {4},
pages = {1029--1040},
title = {{An Algorithm for Computing the Exact Distribution of the Kruskal-Wallis Test}},
volume = {32},
year = {2003}
}
@misc{Jamovi2022,
address = {Sydney, Australia},
author = {{The Jamovi Project}},
title = {jamovi},
url = {https://www.jamovi.org},
year = {2022}
}
@Manual{Rproject,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2022},
    url = {https://www.R-project.org/},
}
@article{Head2015,
author = {Head, Megan L and Holman, Luke and Lanfear, Rob and Kahn, Andrew T and Jennions, Michael D},
doi = {10.1371/journal.pbio.1002106},
file = {:home/brad/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Head et al. - 2015 - The extent and consequences of p-hacking in science.pdf:pdf},
issn = {1545-7885},
journal = {PLoS Biology},
number = {3},
pages = {e1002106},
title = {{The extent and consequences of p-hacking in science}},
url = {http://dx.plos.org/10.1371/journal.pbio.1002106},
volume = {13},
year = {2015}
}
@article{Tate1973,
abstract = {In applied statistics there is an increasing tendency toward leniency regarding minimum expectation prerequisite to Pearson's X2 test for goodness of fit, based on various empirical studies of the distribution of X2 in sampling from multinomial populations with given parameters. In this study it is shown that the chi-square probabilities of X2 may differ markedly from the exact cumulative multinomial probabilities. Contrary to prevailing opinion, the approximation did not improve, when samples were small, as expectation increased nor as the number of categories or degrees of freedom increased. {\textcopyright} Taylor & Francis Group, LLC.},
author = {Tate, Merle W and Hyer, Leon A},
doi = {10.1080/01621459.1973.10481433},
file = {:home/brad/Dropbox/papers/Tate_Hyer1973.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {344},
pages = {836--841},
title = {{Inaccuracy of the X2 test of goodness of fit when expected frequencies are small}},
volume = {68},
year = {1973}
}
@article{Slakter1968,
abstract = {This paper presents the results of a Monte Carlo study of the accuracy of an approximation to the power of the chi-square goodness of fit test with small but equal expected frequencies. Various combinations of sample size, number of groups, and alpha level are considered, and in most instances the actual power of the test is estimated to be less than the nominal power. The degree of accuracy appears to be more related to the size of the sample than to the size of the expected frequencies. The following rule of thumb is offered for obtaining crude estimates of the actual power from the nominal power for sample sizes from 10 to 50. The actual power of the test equals about eight-tenths of the nominal power. Copyright Taylor & Francis.},
author = {Slakter, Malcolm J.},
doi = {10.1080/01621459.1968.11009319},
file = {:home/brad/Dropbox/papers/Slakter1968.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {323},
pages = {912--918},
title = {{Accuracy of an Approximation to the Power of the Chi-Square Goodness of Fit Test with Small but Equal Expected Frequencies}},
volume = {63},
year = {1968}
}
@book{Rahman1968,
author = {Rahman, N A},
pages = {542},
publisher = {Charles Griffin and Company},
title = {{A Course in Theoretical Statistics}},
year = {1968}
}
@article{Burrows2022,
abstract = {Exposure to radiation is a natural part of our environment. Yet, due to nuclear accidents such as at Chernobyl, some organisms are exposed to significantly elevated dose rates. Our understanding of the effects of radiation in the environment is limited, confounded by substantial interspecific differences in radio-sensitivity and conflicting findings. Here we study radiation impacts on bumblebees in the laboratory using principles from life-history theory, which assume organismal investment in fitness-related traits is constrained by resource availability and resource allocation decisions. To investigate how chronic radiation might negatively affect life-history traits, we tested whether exposure affects bumblebee energy budgets by studying resource acquisition (feeding) and resource use (metabolic rate). We monitored metabolic rate, movement and nectar intake of bumblebees before, during and after 10 days of radiation exposure. Subsequently, we monitored feeding and body mass across a dose rate gradient to investigate the dose rate threshold for these effects. We studied dose rates up to 200 $\mu$Gy/hr: a range found today in some areas of the Chernobyl Exclusion Zone. Chronic low-dose radiation affected bumblebee energy budgets. At 200 $\mu$Gy/hr nectar consumption elevated by 56% relative to controls, metabolic CO2 production increased by 18%, and time spent active rose by 30%. Once radiation exposure stopped, feeding remained elevated but CO2 production and activity returned to baseline. Our analysis indicates that elevated metabolic rate was not driven by increased activity but was instead closely associated with feeding increases. Our data suggest bumblebee nectar consumption was affected across the 50–200 $\mu$Gy/hr range. We show field-realistic radiation exposure influences fundamental metabolic processes with potential to drive changes in many downstream life-history traits. We hypothesise that radiation may trigger energetically costly repair mechanisms, increasing metabolic rate and nectar requirements. This change could have significant ecological consequences in contaminated landscapes, including Chernobyl. We demonstrate bumblebees are more sensitive to radiation than assumed by existing international frameworks for environmental radiological protection. Read the free Plain Language Summary for this article on the Journal blog.},
author = {Burrows, Jessica E. and Copplestone, David and Raines, Katherine E. and Beresford, Nicholas A. and Tinsley, Matthew C.},
doi = {10.1111/1365-2435.14067},
file = {:home/brad/Dropbox/papers/BurrowsEtAl2022.pdf:pdf},
issn = {13652435},
journal = {Functional Ecology},
keywords = {Ionising radiation,eco-toxicology,energy budget,insects,life history,pollinator,radiological contamination,resource allocation},
number = {8},
pages = {1822--1833},
title = {{Ecologically relevant radiation exposure triggers elevated metabolic rate and nectar consumption in bumblebees}},
volume = {36},
year = {2022}
}
